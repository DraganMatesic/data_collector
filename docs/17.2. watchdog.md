[← Back to index](1.%20index.md)

# WatchService — File System Monitoring

**Phase:** 4 (v0.4.0)

## Overview

The WatchService monitors directories for new files and writes events to the `Events` table. It is an **event producer** — it does not dispatch to Dramatiq directly. The TaskDispatcher ([17.1. dramatiq.md](17.1.%20dramatiq.md)) polls the Events table and handles Dramatiq dispatch.

```
WatchService                    Events Table              TaskDispatcher
(file system monitoring)        (database)                (Dramatiq dispatch)
      │                              │                          │
      ▼                              ▼                          ▼
  Detect file ──► Write event ──► Unprocessed ──► Dispatch to Dramatiq
  creation        to Events       event row        via RabbitMQ
```

**Dependencies:** `watchdog`

Developed and tested primarily on Windows, but fully deployable on Linux.

## watchdog Library

The framework uses the `watchdog` library for file system monitoring. watchdog wraps native OS APIs for near-instant event delivery:

| Platform | Observer Class | Underlying OS API | Notes |
|----------|---------------|-------------------|-------|
| Windows | `WindowsApiObserver` | `ReadDirectoryChangesW` | I/O completion ports. Vista+. Requires `pywin32` |
| Linux | `InotifyObserver` | `inotify(7)` | Kernel 2.6.13+. Default 8,192 watch limit per user |
| macOS | `FSEventsObserver` | Apple FSEvents | `KqueueObserver` as fallback |
| All | `PollingObserver` | `os.stat()` polling | Fallback for Docker volumes, network drives |

## Dataclasses

```python
from dataclasses import dataclass, field
from enum import IntEnum

class EventType(IntEnum):
    CREATED = 1
    MODIFIED = 2
    DELETED = 3

@dataclass
class Root:
    """Configuration for a single watched directory root."""
    root_id: int
    root_path: str
    rel_path: str              # Relative path identifier
    country: str               # Country code for pipeline routing
    watch_group: str           # Logical grouping (e.g., "ocr", "ingest")
    extensions: list[str] | None = None  # Allowed extensions (None = all)
    recursive: bool = True

@dataclass
class EventData:
    """Rich event context passed to the event handler."""
    abs_path: str
    root_data: Root
    event_type: EventType
    path_hash: str             # SHA hash of normalized path
    disallowed: int = 0        # 1 if extension not in root's allow list
    file_size: int | None = None
```

## EventHandler (Abstract)

Clean separation — WatchService handles file system complexity, application code implements `process()`:

```python
from abc import ABC, abstractmethod

class EventHandler(ABC):
    """Application-level handler for file system events."""

    @abstractmethod
    def process(self, event_data: EventData) -> None:
        """Process a single file event — typically writes to Events table."""
        ...
```

The default `IngestEventHandler` writes events to the `Events` table:

```python
class IngestEventHandler(EventHandler):
    """Writes file events to the Events table for TaskDispatcher pickup."""

    def __init__(self, database: Database):
        self.database = database

    def process(self, event_data: EventData) -> None:
        with self.database.create_session() as session:
            event = Events(
                file_path=event_data.abs_path,
                event_type=event_data.event_type,
                path_hash=event_data.path_hash,
                country=event_data.root_data.country,
                watch_group=event_data.root_data.watch_group,
                file_size=event_data.file_size,
                app_path=self._resolve_app_path(event_data)
            )
            session.add(event)
            session.commit()
```

## WatchService

Multi-root, thread-safe file watcher with production-hardened features:

```python
from watchdog.events import FileSystemEventHandler
from collections import OrderedDict
from pathlib import Path
import threading

class WatchdogAdapter(FileSystemEventHandler):
    """Stateless adapter — forwards watchdog events to WatchService."""

    def __init__(self, watch_service: "WatchService"):
        self.watch_service = watch_service

    def on_created(self, event):
        if not event.is_directory:
            self.watch_service.handle_path(event.src_path, EventType.CREATED)

    def on_modified(self, event):
        if not event.is_directory:
            self.watch_service.handle_path(event.src_path, EventType.MODIFIED)

    def on_deleted(self, event):
        if not event.is_directory:
            self.watch_service.handle_path(event.src_path, EventType.DELETED)


class WatchService:
    """Multi-root directory watcher with stability debounce and deduplication."""

    def __init__(self, roots: list[Root], event_handler: EventHandler,
                 debounce: float = 2.0, dedup_ttl: float = 30.0):
        self.roots = {r.root_path: r for r in roots}
        self.event_handler = event_handler
        self.debounce = debounce
        self.dedup_ttl = dedup_ttl

        self._seen_recently: OrderedDict[str, float] = OrderedDict()
        self._seen_lock = threading.Lock()
        self._pending_stability: dict[str, dict] = {}
        self._pending_lock = threading.Lock()
        self._observer = None
```

### Platform-Aware Observer Selection

```python
def _create_observer(self, observer_type: str = "auto"):
    """Select observer based on platform with graceful fallback."""
    if observer_type == "polling":
        from watchdog.observers.polling import PollingObserver
        return PollingObserver(timeout=self.poll_interval)

    if sys.platform == "win32":
        try:
            from watchdog.observers import Observer  # WindowsApiObserver
            return Observer()
        except ImportError:
            logger.warning("pywin32 not installed, falling back to PollingObserver")
            from watchdog.observers.polling import PollingObserver
            return PollingObserver(timeout=self.poll_interval)
    else:
        try:
            from watchdog.observers import Observer  # InotifyObserver on Linux
            return Observer()
        except Exception:
            from watchdog.observers.polling import PollingObserver
            return PollingObserver(timeout=self.poll_interval)
```

### File Stability Debounce

Prevents processing half-written files by checking file size twice with a delay:

```python
def _is_stable(self, file_path: str) -> bool:
    """Check if file has finished writing (size stable between two checks)."""
    try:
        s1 = os.path.getsize(file_path)
        time.sleep(self.debounce / 2)
        s2 = os.path.getsize(file_path)
        return s1 == s2 and s1 > 0
    except OSError:
        return False
```

Files that aren't stable on first check are deferred to a background stability monitor thread that re-checks periodically with a configurable timeout (default 60s):

```python
def _monitor_stability(self):
    """Background thread — re-checks deferred files until stable or timed out."""
    while not self._stop_event.is_set():
        with self._pending_lock:
            now = time.time()
            expired = []
            for path, info in self._pending_stability.items():
                if now - info["first_seen"] > self.stability_timeout:
                    expired.append(path)
                    logger.warning("Stability timeout", path=path)
                elif self._is_stable(path):
                    self._process_event(path, info["root"], info["event_type"])
                    expired.append(path)
            for path in expired:
                del self._pending_stability[path]
        self._stop_event.wait(timeout=self.debounce)
```

### TTL-Based Deduplication

Prevents duplicate processing from multiple OS events for the same file operation:

```python
def _is_duplicate(self, dedup_key: str) -> bool:
    """Check if event was recently processed (TTL-based dedup)."""
    now = time.time()
    with self._seen_lock:
        # Purge expired entries
        while self._seen_recently:
            oldest_key, oldest_time = next(iter(self._seen_recently.items()))
            if now - oldest_time > self.dedup_ttl:
                del self._seen_recently[oldest_key]
            else:
                break

        if dedup_key in self._seen_recently:
            return True
        self._seen_recently[dedup_key] = now
        return False
```

### UNC Path Normalization

Handles Windows enterprise network paths (`\\server\share`), forward/backward slashes, and long paths (>248 chars):

```python
def _normalize_path(self, path: str) -> str:
    """Normalize path for consistent hashing and dedup."""
    path = path.replace("/", "\\") if sys.platform == "win32" else path
    if sys.platform == "win32" and path.startswith("\\\\"):
        # UNC path normalization
        path = "\\\\?" + path[1:]  if len(path) > 248 else path
    return os.path.normpath(path)
```

### Event Processing Flow

```python
def handle_path(self, file_path: str, event_type: EventType):
    """Main entry point — called by WatchdogAdapter for each FS event."""
    file_path = self._normalize_path(file_path)

    # Find which root this path belongs to
    root = self._find_root(file_path)
    if root is None:
        return

    # Extension filtering
    if root.extensions and not self._is_allowed(file_path, root.extensions):
        return

    # File size and hash
    try:
        file_size = os.path.getsize(file_path)
    except OSError:
        file_size = None
    path_hash = make_hash(file_path)

    # Dedup check
    dedup_key = f"{path_hash}-{event_type}"
    if self._is_duplicate(dedup_key):
        return

    # Stability check (skip for DELETE events)
    if event_type != EventType.DELETED and not self._is_stable(file_path):
        with self._pending_lock:
            self._pending_stability[file_path] = {
                "root": root, "event_type": event_type,
                "first_seen": time.time()
            }
        return

    self._process_event(file_path, root, event_type)

def _process_event(self, file_path: str, root: Root, event_type: EventType):
    """Forward stable, deduplicated event to the application handler."""
    event_data = EventData(
        abs_path=file_path,
        root_data=root,
        event_type=event_type,
        path_hash=make_hash(file_path),
        file_size=os.path.getsize(file_path) if os.path.exists(file_path) else None
    )
    self.event_handler.process(event_data)
```

### Starting the WatchService

```python
from data_collector.pipeline.watch_service import WatchService, Root, IngestEventHandler

# Configure watched roots
roots = [
    Root(root_id=1, root_path="/ingest/croatia/eoglasna",
         rel_path="eoglasna", country="HR", watch_group="ocr",
         extensions=[".pdf", ".zip"]),
    Root(root_id=2, root_path="/ingest/croatia/contracts",
         rel_path="contracts", country="HR", watch_group="ocr",
         extensions=[".pdf"]),
]

# Create handler that writes to Events table
handler = IngestEventHandler(database)

# Start watch service
service = WatchService(roots, handler, debounce=2.0, dedup_ttl=30.0)
service.start()
```

## Production Mitigations

Watchdog events are **signals, not guarantees**. The framework treats them as hints and uses database-level idempotency (via `EventProcessingStatus`) to handle all edge cases safely:

| Scenario | Issue | Mitigation |
|----------|-------|------------|
| Windows high throughput | `ReadDirectoryChangesW` buffer overflow — events silently dropped | Periodic reconciliation scan (configurable interval, default 60s) re-scans directories and dispatches any files missing from `Events` table |
| Docker (Linux container + Windows host volume) | `inotify` receives no events for host-side changes | Auto-fallback to `PollingObserver` via `watcher_observer=polling` setting or `DC_WATCHER_OBSERVER=polling` env var |
| Linux production | Default 8,192 inotify watch limit | Set `fs.inotify.max_user_watches=524288` in `/etc/sysctl.conf` or Docker base image |
| Network drives (CIFS/SMB) | Native observers may not receive events | Use `PollingObserver` explicitly; implement reconnection in watcher service |
| Half-written files | Large files (PDF, ZIP) arrive over network — partial read | File stability debounce: size-check-twice with configurable delay |
| Duplicate OS events | Multiple `CREATED`/`MODIFIED` events for single file write | TTL-based dedup via `_seen_recently` OrderedDict |
| All environments | Events are signals, not guarantees | DB-level dispatch tracking — `EventProcessingStatus` prevents double Dramatiq dispatch regardless of how many times the event is written |

## Reconciliation Scanner

A background thread periodically scans all watched directories and writes events for any files not yet tracked in the `Events` table. This catches files missed due to buffer overflow, watcher restart, or manual file placement:

```python
def reconcile(self):
    """Periodic full-directory scan to catch missed events."""
    for root in self.roots.values():
        root_path = Path(root.root_path)
        for file_path in root_path.rglob("*") if root.recursive else root_path.iterdir():
            if not file_path.is_file():
                continue
            if root.extensions and file_path.suffix.lower() not in root.extensions:
                continue

            path_hash = make_hash(str(file_path))
            # Check if already in Events table
            with self.database.create_session() as session:
                exists = session.execute(
                    select(func.count()).select_from(Events)
                    .where(Events.path_hash == path_hash)
                ).scalar()
                if exists == 0:
                    self.handle_path(str(file_path), EventType.CREATED)
```

## Configuration

| Setting | Default | Description |
|---------|---------|-------------|
| `watcher_observer` | `auto` | Observer type: `auto` (native OS API), `polling` (fallback for Docker volumes, network drives) |
| `watcher_poll_interval` | `5` | Polling interval in seconds (only used with `PollingObserver`) |
| `watcher_reconcile_interval` | `60` | Seconds between full directory reconciliation scans |
| `watcher_debounce` | `2.0` | Seconds for file stability debounce (size-check-twice) |
| `watcher_dedup_ttl` | `30.0` | Seconds to keep events in dedup cache |
| `watcher_stability_timeout` | `60` | Seconds before giving up on unstable files |
| `watched_dirs_root` | `./watched` | Base directory containing watched subdirectories |

## Dependencies

- **watchdog** — Cross-platform file system monitoring (native OS APIs + polling fallback)
- TaskDispatcher ([17.1. dramatiq.md](17.1.%20dramatiq.md)) — consumes events from Events table
- RabbitMQ infrastructure ([17. rabbitmq.md](17.%20rabbitmq.md))
