[← Back to index](1.%20index.md)

# Deep Learning / NER for Entity Extraction

**Implementation Status:** PLANNED | **Phase:** 5 (v0.5.0)

## Overview

Named Entity Recognition (NER) for extracting structured data from OCR text and scraped HTML. Uses pre-trained and fine-tuned models to identify company names, person names, addresses, financial figures, and other entities in unstructured text.

## Use Cases

| Entity Type | Source | Example |
|------------|--------|---------|
| Company names | OCR text, HTML | "Acme Corporation d.o.o." |
| Person names & roles | Court documents | "Director: Ivan Horvat" |
| Addresses | Registration documents | "Ilica 1, 10000 Zagreb" |
| Financial figures | Financial statements | "Revenue: EUR 1,234,567" |
| Dates & references | Legal documents | "OIB: 12345678901, 15.01.2025" |
| Registration numbers | Government registries | "MBS: 080123456" |

## Scope Boundary

The framework provides **infrastructure** for NER processing. Developers build specific NER models and workers tailored to each document type, country, and language.

**Framework provides:**
- Utility wrappers for spaCy, GLiNER, and Hugging Face transformers
- Base worker class for NER processing (`BaseNERWorker`)
- Dramatiq task routing via RabbitMQ (one topic per document type or entity domain)
- Integration with `Database.merge()` ([4.1. database.md](4.1.%20database.md#database-merge)) for persisting extracted entities

**Developers build:**
- Specific NER models per document type / country / language
- Custom workers extending `BaseNERWorker` with domain-specific extraction logic
- Training data annotation and model fine-tuning for their domain

## Dramatiq Worker Integration

NER processing runs as **Dramatiq workers** ([17.1. dramatiq.md](17.1.%20dramatiq.md)) dispatched via the two-layer model — upstream pipeline actors or the WatchService ([17.2. watchdog.md](17.2.%20watchdog.md)) write events to the `Events` table, and the TaskDispatcher dispatches to NER workers via RabbitMQ:

```
OCR Text / Scraped HTML
         │
         ▼
   Event written to Events table
   (by upstream pipeline actor or WatchService [17.2])
         │
         ▼
   TaskDispatcher [17.1] polls Events table
         │
         ▼
   Dramatiq message dispatched via RabbitMQ
   (routing key: e.g., "ocr.extracted.eoglasna")
         │
         ▼
   NER Worker (domain-specific actor)
   ├── Check EventProcessingStatus (idempotent)
   ├── Fetch extracted text from DB by event_id
   ├── Load spaCy / GLiNER / transformer model
   ├── Extract entities
   ├── Post-process (dedup, normalize, validate)
   └── Persist via Database.merge()
```

**Example worker** (matches patterns in [17.1. dramatiq.md](17.1.%20dramatiq.md#domain-specific-actors)):
```python
import dramatiq
from data_collector.pipeline.topics.croatia import NER_COMPANY_REGISTRATION

@dramatiq.actor(queue_name=NER_COMPANY_REGISTRATION.name, max_retries=3,
                on_retry_exhausted="log_dead_letter")
def process_company_registration(event_id: int):
    """Domain-specific NER worker for company registration documents."""
    database = Database(MainDatabaseSettings())

    with database.create_session() as session:
        # Idempotency check
        existing = session.execute(
            select(EventProcessingStatus)
            .where(EventProcessingStatus.event_id == event_id,
                   EventProcessingStatus.actor_name == "process_company_registration")
        ).scalar_one_or_none()
        if existing:
            return

        # Fetch extracted text from previous pipeline stage
        texts = session.execute(
            select(ExtractedText)
            .where(ExtractedText.event_id == event_id)
        ).scalars().all()

        worker = CompanyRegistrationNERWorker()
        for text_record in texts:
            entities = worker.extract(text_record.content)
            worker.persist(session, event_id, entities)

        # Mark as processed
        session.add(EventProcessingStatus(
            event_id=event_id,
            actor_name="process_company_registration",
            processed_at=datetime.now()
        ))
        session.commit()
```

## Recommended Architecture

### Tiered Approach

**Tier 1 — Rule-Based + Pre-trained (start here):**
- spaCy pre-trained models for common entities (PERSON, ORG, GPE, DATE)
- spaCy `EntityRuler` for pattern-based extraction (regex for OIB, MBS, phone numbers)
- Fast, deterministic, no training data needed

**Tier 2 — Fine-tuned Models (when Tier 1 isn't enough):**
- Fine-tune spaCy or Hugging Face transformers on domain-specific annotated data
- ~200+ annotated samples per entity type
- Higher accuracy for domain-specific entities

**Tier 3 — Zero-Shot Discovery (for new/unknown entity types):**
- GLiNER for discovering entity types without annotation
- Useful when processing new document types
- More robust to OCR errors than traditional NER

### Pipeline Architecture

```
OCR Text / HTML Content
         │
         ▼
   Preprocessing
   (clean whitespace, normalize encoding)
         │
         ▼
   ┌─────┴─────┐
   ▼            ▼
EntityRuler  spaCy NER
(patterns)   (pre-trained)
   │            │
   └─────┬──────┘
         ▼
   Entity Post-processing
   (dedup, normalize, validate)
         │
         ▼
   Confidence Scoring
         │
         ▼
   Structured Output → ORM objects → Database.merge()
```

## Recommended Libraries

| Library | Version | Purpose |
|---------|---------|---------|
| **spaCy** | 3.7+ | Production NER pipeline, EntityRuler, training |
| **Hugging Face transformers** | 4.36+ | Fine-tuned BERT models for domain NER |
| **GLiNER** | 2.1+ | Zero-shot NER without training data |

### spaCy Models

| Model | Size | Entities | Speed |
|-------|------|----------|-------|
| `en_core_web_sm` | 12 MB | Basic NER | Fastest |
| `en_core_web_lg` | 560 MB | Better NER + word vectors | Medium |
| `en_core_web_trf` | 438 MB | Transformer-based, best accuracy | Slowest |

For multi-language support (Balkan languages), consider training custom models or using multilingual transformers.

## Custom NER Training Pipeline

### Data Annotation
1. Collect ~200+ examples per entity type from real documents
2. Annotate using spaCy's format or Prodigy annotation tool
3. Store training data in DocBin format (`.spacy` files)

### Training
```bash
# Generate training config
python -m spacy init config config.cfg --lang en --pipeline ner

# Train the model
python -m spacy train config.cfg --output ./models/custom_ner
```

### Evaluation Metrics
- **Precision:** % of predicted entities that are correct
- **Recall:** % of actual entities that were found
- **F1 Score:** Harmonic mean of precision and recall
- Target: F1 > 0.85 for production use

## Integration with Framework

```python
import spacy

nlp = spacy.load("./models/custom_ner")

# Process OCR output
doc = nlp(ocr_text)

# Extract entities → ORM objects
for ent in doc.ents:
    if ent.label_ == "COMPANY":
        record = CompanyEntity(
            name=ent.text,
            source_document=document_id,
            confidence=ent._.confidence  # custom extension
        )
```

## Dependencies (to be added)

| Package | Purpose |
|---------|---------|
| `spacy` | NER pipeline and training |
| `transformers` | Hugging Face model access |
| `gliner` | Zero-shot NER |
| `torch` | PyTorch backend for transformers |
| `dramatiq` | Worker task queue ([17.1. dramatiq.md](17.1.%20dramatiq.md)) |

## Related Docs

- [14. pdf-ocr.md](14.%20pdf-ocr.md) — OCR text extraction feeding into NER
- [17.1. dramatiq.md](17.1.%20dramatiq.md) — Task processing, worker patterns, pipeline routing
- [17.2. watchdog.md](17.2.%20watchdog.md) — File system monitoring (event production for NER pipeline)
