[← Back to index](1.%20index.md)

# Notification System

**Phase:** 4 (v0.4.0)

## Overview

The notification system provides real-time alerting when apps crash, hit fatal states, or require operator attention. It is built as a **pluggable architecture** — multiple notification channels can be enabled simultaneously, and new channels can be added without modifying existing code.

Developed and tested primarily on Windows, but fully deployable on Linux.

## Architecture

### BaseNotifier Interface

All notification channels implement the `BaseNotifier` abstract class:

```python
from abc import ABC, abstractmethod
from dataclasses import dataclass

from data_collector.enums.notifications import AlertSeverity

@dataclass
class Notification:
    severity: AlertSeverity
    title: str
    message: str
    app_id: str | None = None
    metadata: dict | None = None

class BaseNotifier(ABC):
    """Base class for all notification channels."""

    @abstractmethod
    def send(self, notification: Notification) -> bool:
        """Send a notification. Returns True on success, False on failure."""
        ...

    @abstractmethod
    def is_configured(self) -> bool:
        """Check whether this channel has valid configuration."""
        ...
```

### Supported Channels

| Channel | Transport | Use Case |
|---------|-----------|----------|
| **Telegram Bot API** | HTTPS (Bot API) | Mobile-friendly alerts for on-call operators |
| **Microsoft Teams** | Incoming Webhooks | Enterprise team collaboration alerts |
| **Slack API** | Web API / Webhooks | Developer-focused team notifications |
| **Email (SMTP)** | SMTP / SMTP+TLS | Formal alerts, audit trail, stakeholder updates |
| **Generic Webhooks** | HTTP POST | Integration with custom dashboards, PagerDuty, etc. |

Each channel implements `BaseNotifier.send()` with a consistent interface. The framework dispatches notifications to all enabled channels in parallel.

## Alert Types

| Alert | Trigger | Severity |
|-------|---------|----------|
| Fatal error | `Apps.fatal_flag` set | CRITICAL |
| App crash | Process terminated unexpectedly | CRITICAL |
| Repeated failure | App failed N times in a row | ERROR |
| Daily summary | Scheduled (e.g., 8 AM) | INFO |
| Custom alert | App-specific conditions | Configurable |

### Alert Severity Levels

Severity levels are defined as `AlertSeverity` IntEnum in the planned module path: `data_collector/enums/notifications.py` (see [1.3. enums.md](1.3.%20enums.md)):

| Value | Level | Description |
|-------|-------|-------------|
| 1 | INFO | Informational messages (daily summaries, status updates) |
| 2 | WARNING | Non-critical issues that may require attention |
| 3 | ERROR | Failures that need operator action |
| 4 | CRITICAL | Fatal errors requiring immediate intervention |

Channels can be configured to only receive alerts at or above a certain severity threshold.

## Message Format

```
CRITICAL: croatia/fina/companies

Status: Failed to start
Time: 2025-01-15 10:30:00 UTC
Last error: Connection refused to registry API
Runtime: 0m 3s

Action required: Check source availability
```

Each channel adapter formats the notification appropriately for its platform (e.g., Markdown for Telegram, Adaptive Cards for Teams, Block Kit for Slack).

## Configuration

### NotificationSettings

Global notification settings plus per-channel configuration:

| Setting | Type | Description |
|---------|------|-------------|
| `notifications_enabled` | Boolean | Master switch for the notification system |
| `notification_channels` | List | Enabled channel names (e.g., `["telegram", "teams", "email"]`) |
| `alert_min_severity` | Integer | Minimum severity level to send (default: WARNING) |
| `daily_summary_enabled` | Boolean | Enable daily summary report |
| `daily_summary_time` | String | Time for daily summary (default: `"08:00"`) |

### Channel-Specific Configuration

#### Telegram Bot API

| Setting | Description |
|---------|-------------|
| `telegram_bot_token` | Bot API token from @BotFather |
| `telegram_chat_id` | Target chat/group ID |

#### Microsoft Teams

| Setting | Description |
|---------|-------------|
| `teams_webhook_url` | Incoming webhook URL for the target channel |

#### Slack API

| Setting | Description |
|---------|-------------|
| `slack_webhook_url` | Slack incoming webhook URL |
| `slack_channel` | Target channel (optional, overrides webhook default) |

#### Email (SMTP)

| Setting | Description |
|---------|-------------|
| `smtp_host` | SMTP server hostname |
| `smtp_port` | SMTP port (default: 587) |
| `smtp_username` | SMTP authentication username |
| `smtp_password` | SMTP authentication password |
| `smtp_from` | Sender address |
| `smtp_to` | Comma-separated list of recipient addresses |
| `smtp_use_tls` | Enable TLS (default: True) |

#### Generic Webhooks

| Setting | Description |
|---------|-------------|
| `webhook_url` | Target URL for HTTP POST |
| `webhook_headers` | Optional custom headers (JSON) |
| `webhook_auth_token` | Optional Bearer token |

## Rate Limiting

Each channel has independent rate limiting to prevent message flooding during cascading failures:

```python
class RateLimiter:
    """Per-channel rate limiting."""
    def __init__(self, min_interval_seconds: int = 30, burst_limit: int = 10):
        self.min_interval = min_interval_seconds
        self.burst_limit = burst_limit
```

- **min_interval** — Minimum seconds between consecutive alerts on a channel
- **burst_limit** — Maximum alerts within a rolling window before throttling

When rate-limited, lower-severity alerts are dropped while CRITICAL alerts are always delivered.

## Retry Logic

Failed deliveries are retried with exponential backoff:

1. First retry: 10 seconds
2. Second retry: 30 seconds
3. Third retry: 90 seconds
4. After 3 failures: mark delivery as failed, log the error

Each delivery attempt is tracked. If a channel consistently fails, it is temporarily disabled and an alert is raised on the remaining working channels.

## Integration

- Triggered by the orchestration Manager when `fatal_flag` changes (set by `BaseScraper.fatal_check()`)
- Alert throttling prevents message flooding during cascading failures
- Uses `requests` library directly for HTTP-based channels (Telegram, Teams, Slack, webhooks) and `smtplib` for email — these are simple notification POST calls, not scraping requests, so the centralized `Request` class is not used here

## Channel Implementations

### Telegram Bot API

```python
class TelegramNotifier(BaseNotifier):
    """Send alerts via Telegram Bot API."""

    def send(self, notification: Notification) -> bool:
        url = f"https://api.telegram.org/bot{self.bot_token}/sendMessage"
        payload = {
            "chat_id": self.chat_id,
            "text": self.format_message(notification),
            "parse_mode": "Markdown"
        }
        response = requests.post(url, json=payload, timeout=10)
        return response.status_code == 200
```

### Microsoft Teams

```python
class TeamsNotifier(BaseNotifier):
    """Send alerts via Microsoft Teams incoming webhook."""

    def send(self, notification: Notification) -> bool:
        card = self.build_adaptive_card(notification)
        response = requests.post(self.webhook_url, json=card, timeout=10)
        return response.status_code == 200
```

### Slack API

```python
class SlackNotifier(BaseNotifier):
    """Send alerts via Slack webhook."""

    def send(self, notification: Notification) -> bool:
        payload = self.build_block_kit(notification)
        response = requests.post(self.webhook_url, json=payload, timeout=10)
        return response.status_code == 200
```

### Email (SMTP)

```python
class EmailNotifier(BaseNotifier):
    """Send alerts via SMTP email."""

    def send(self, notification: Notification) -> bool:
        msg = self.build_email(notification)
        with smtplib.SMTP(self.host, self.port) as server:
            if self.use_tls:
                server.starttls()
            server.login(self.username, self.password)
            server.send_message(msg)
        return True
```

### Generic Webhook

```python
class WebhookNotifier(BaseNotifier):
    """Send alerts via generic HTTP webhook."""

    def send(self, notification: Notification) -> bool:
        payload = {
            "severity": notification.severity.name,
            "title": notification.title,
            "message": notification.message,
            "app_id": notification.app_id,
            "timestamp": datetime.utcnow().isoformat()
        }
        headers = {**self.custom_headers}
        if self.auth_token:
            headers["Authorization"] = f"Bearer {self.auth_token}"
        response = requests.post(self.url, json=payload, headers=headers, timeout=10)
        return response.status_code in (200, 201, 202, 204)
```

## Adding a New Notification Channel

To add a new channel (e.g., PagerDuty, Discord):

1. **Create the notifier class** extending `BaseNotifier`:
   ```python
   # Planned module path: data_collector/notifications/pagerduty.py
   from data_collector.notifications.base import BaseNotifier, Notification

   class PagerDutyNotifier(BaseNotifier):
       def send(self, notification: Notification) -> bool:
           # Implementation here
           ...

       def is_configured(self) -> bool:
           return bool(self.routing_key)
   ```

2. **Add configuration settings** for the channel credentials

3. **Register the channel** in the notification dispatcher so it is discovered when enabled

4. **Add the channel name** to the `notification_channels` list in settings to activate it

The pluggable design means no existing code needs to change when a new channel is added.

## Dependencies

- **requests** — HTTP client for Telegram, Teams, Slack, and webhook channels
- **smtplib** (stdlib) — SMTP email delivery
- Orchestration manager ([10. orchestration.md](10.%20orchestration.md))
