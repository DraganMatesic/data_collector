[← Back to index](1.%20index.md) | [← Getting Started](30.%20getting-started.md)

# Building Your First App

This tutorial walks through creating a complete data collection app using the framework.

## App Anatomy

Every Data Collector app has three concerns:

1. **ORM Model** — defines the database table for collected data
2. **Collection Logic** — fetches data from a source (web, API, file)
3. **Framework Integration** — uses `Database.merge()` for sync, `LoggingService` for logging

## Step-by-Step Tutorial

### Step 1: Define Your ORM Model

Create a table to store the collected data:

```python
# apps/example/companies/tables.py
from sqlalchemy import Column, String, Integer, DateTime, func
from data_collector.tables.shared import Base
from data_collector.utilities.database.main import auto_increment_column

class Companies(Base):
    __tablename__ = 'example_companies'

    id = auto_increment_column()
    name = Column(String(256), index=True)
    country = Column(String(50))
    reg_number = Column(String(50))
    status = Column(String(50))
    sha = Column(String(64), index=True)
    archive = Column(DateTime, comment="When removed from source")
    date_created = Column(DateTime, server_default=func.now())
```

Key elements:
- `id` — auto-increment PK via `auto_increment_column()` (works on Postgres/MSSQL)
- `sha` — hash column for `merge()` change detection
- `archive` — timestamp column for archiving removed records
- `date_created` — auto-populated creation timestamp

### Step 2: Create the Collection Logic

```python
# apps/example/companies/main.py
from datetime import datetime
from sqlalchemy import and_

from data_collector.utilities.database.main import Database
from data_collector.utilities.log.main import LoggingService
from data_collector.utilities.functions.runtime import bulk_hash
from data_collector.settings.main import MainDatabaseSettings

# Import your table
from apps.example.companies.tables import Companies


def collect_companies():
    """Fetch company data and sync with database."""

    # --- Setup ---
    database = Database(MainDatabaseSettings())

    log_service = LoggingService(
        logger_name="example.companies",
        db_engine=database.engine
    )
    logger = log_service.configure_logger()

    logger.info("Starting company collection")

    # --- Collect data from source ---
    # In real apps, this comes from web scraping, API calls, file parsing, etc.
    source_data = [
        Companies(name="Acme Corp", country="HR", reg_number="12345678", status="Active"),
        Companies(name="Global Ltd", country="HR", reg_number="87654321", status="Active"),
        Companies(name="New Startup", country="HR", reg_number="11223344", status="Active"),
    ]

    # --- Hash all records ---
    bulk_hash(source_data)
    logger.info("Collected records from source", count=len(source_data))

    # --- Sync with database ---
    with database.create_session() as session:
        filters = and_(Companies.country == "HR")

        stats = database.merge(
            objs=source_data,
            session=session,
            filters=filters,
            stats=True,
            logger=logger
        )

        logger.info("Merge complete",
                    inserted=stats.inserted,
                    archived=stats.archived,
                    total=stats.number_of_records)

    # --- Cleanup ---
    log_service.stop()


if __name__ == "__main__":
    collect_companies()
```

### Step 3: Deploy Your Table

Before running, create the table in the database:

```python
from data_collector.tables.deploy import Deploy
from apps.example.companies.tables import Companies

# Deploy creates all Base tables, including your new one
api = Deploy()
api.create_tables()
```

### Step 4: Run

```bash
python -m apps.example.companies.main
```

Expected output:
```
2025-01-15 10:30:00 INFO example.companies Starting company collection
2025-01-15 10:30:00 INFO example.companies Collected 3 records from source
2025-01-15 10:30:01 INFO example.companies Merge complete: inserted=3, archived=0, total=3
```

Run again — zero inserts (data unchanged):
```
2025-01-15 10:31:00 INFO example.companies Merge complete: inserted=0, archived=0, total=3
```

## Understanding merge()

The `merge()` method is the core synchronization mechanism:

```
Source: [A, B, C]    Database: [A, B, D]
                     ↓
    obj_diff() via SHA comparison:
    - to_insert: [C]     (new in source)
    - to_remove: [D]     (missing from source)
                     ↓
    Result:
    - C is inserted
    - D is archived (archive column set to current timestamp)
    - A, B unchanged
```

**Filters are critical** — they define the scope of comparison:
```python
# Compare against ALL HR companies:
filters = and_(Companies.country == "HR")

# Compare against a specific company's records:
filters = and_(Companies.reg_number == "12345678")

# No filter = compare against ALL records in the table:
stats = database.merge(objs=source_data, session=session, stats=True)
```

## Common Patterns

### API Consumer

```python
from data_collector.utilities.request.main import Request
from data_collector.utilities.functions.runtime import bulk_hash

request = Request(timeout=30)
response = request.get("https://api.example.com/companies")
data = response.json()

objects = [Companies(**item) for item in data]
bulk_hash(objects)

with database.create_session() as session:
    database.merge(objects, session, stats=True)
```

### File Processor

```python
import pandas as pd

df = pd.read_csv("companies.csv")
objects = [Companies(**row) for row in df.to_dict(orient="records")]
bulk_hash(objects)

with database.create_session() as session:
    database.merge(objects, session, stats=True)
```

### Update-Insert (Upsert) Pattern

When you want to update existing records instead of archive/insert:

```python
with database.create_session() as session:
    stats = database.update_insert(
        objects=source_data,
        session=session,
        filter_cols=['reg_number']  # Match on registration number
    )
    print(f"Inserted: {stats.inserted}, Updated: {stats.updated}")
```

## Next Steps

- [32. App Patterns & Best Practices](32.%20app-patterns.md) — Advanced patterns
- [4.1. Database](4.1.%20database.md) — Full Database class reference
- [4.2. Hashing](4.2.%20hashing.md) — Hash configuration options
- [5. Logging](5.%20logging.md) — Advanced logging setup
