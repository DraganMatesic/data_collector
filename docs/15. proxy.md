[← Back to index](1.%20index.md)

# Proxy Management

**Implementation Status:** In Development | **Phase:** 3 (v0.3.0)

## Overview

Proxy management for web scraping with IP verification and domain-level reservation. The framework integrates with commercial proxy services (BrightData, Oxylabs, Smartproxy, NetNut) that handle IP selection and rotation automatically via super-proxy gateways. The framework's responsibility is:

1. **Build proxy URLs** via a pluggable `ProxyProvider` interface
2. **Verify the assigned IP** via proxy judges with failover
3. **Reserve the IP** in the database so apps hitting the same target domain don't collide
4. **Release the reservation** on thread/session completion, with TTL-based auto-expiry for crash safety

Built from the ground up based on enterprise experience with residential proxy services and government portal scraping across multiple countries.

## Architecture

```
┌──────────────────────────────────────────────────────────┐
│                      ProxyManager                         │
│                                                           │
│  ┌──────────────────┐     ┌───────────────────────────┐  │
│  │  ProxyProvider    │     │   ProxyReservation        │  │
│  │  (interface)      │     │   (database table)        │  │
│  │                   │     │                           │  │
│  │  build_proxy_url  │     │  ip_address               │  │
│  │  (session_id)     │     │  target_domain            │  │
│  │                   │     │  app_id                   │  │
│  │  Implementations: │     │  reserved_at              │  │
│  │  ├─ BrightData    │     │  ttl_seconds              │  │
│  │  ├─ Oxylabs       │     │  released                 │  │
│  │  └─ Custom        │     └───────────────────────────┘  │
│  └────────┬─────────┘                                     │
│           │                                               │
│           v                                               │
│  ┌──────────────────┐     ┌───────────────────────────┐  │
│  │  Proxy Judges     │     │  Request.set_proxy()      │  │
│  │  (IP verification │     │  (consumer)               │  │
│  │  with failover)   │     │                           │  │
│  └──────────────────┘     └───────────────────────────┘  │
└──────────────────────────────────────────────────────────┘
```

**How it works:**

1. `ProxyManager.acquire()` generates a new session ID
2. `ProxyProvider.build_proxy_url(session_id)` constructs the provider-specific proxy URL
3. A proxy judge verifies the actual IP address assigned by the provider
4. The IP is checked against the `ProxyReservation` table for the target domain
5. If available, the IP is reserved; if not, a new session is tried
6. On completion, `ProxyManager.release()` marks the reservation as released
7. Stale reservations (crashed apps) auto-expire via TTL

## ProxyData Dataclass

All proxy configuration lives in a single `ProxyData` dataclass — passed to providers, stored on `BaseScraper`, and used throughout the proxy management system:

```python
from dataclasses import dataclass

@dataclass
class ProxyData:
    """Centralized proxy configuration."""
    host: str                              # Gateway hostname (e.g., "zproxy.lum-superproxy.io")
    port: int                              # Gateway port (e.g., 22225)
    username: str                          # Provider account username
    password: str                          # Provider account password
    country: str | None = None             # Geo-targeting (e.g., "hr", "us", "de")
    protocol: str = "http"                 # http, https, socks5
```

## Proxy Dataclass

`ProxyManager.acquire()` returns a `Proxy` object — a structured result with named fields instead of a raw tuple:

```python
from dataclasses import dataclass

@dataclass
class Proxy:
    """Acquired proxy with verified IP and reservation metadata."""
    url: dict[str, str]           # {"http": "...", "https": "..."} — ready for Request.set_proxy()
    ip_address: str               # Verified IP from proxy judge
    session_id: str               # Provider session ID (for debugging/logging)
    target_domain: str            # Which domain this proxy is reserved for
```

## ProxyProvider Interface

All major residential proxy services (BrightData, Oxylabs, Smartproxy, NetNut) use the same super-proxy gateway model — you connect to a single endpoint and the provider assigns an IP. The only difference between providers is the proxy URL format. The `ProxyProvider` interface abstracts this:

```python
from abc import ABC, abstractmethod

class ProxyProvider(ABC):
    """Interface for proxy service providers."""

    def __init__(self, proxy_data: ProxyData):
        self.proxy_data = proxy_data

    @abstractmethod
    def build_proxy_url(self, session_id: str) -> dict[str, str]:
        """Build proxy URL dict for a given session ID.

        Args:
            session_id: Unique session identifier for IP pinning.

        Returns:
            {"http": "http://...", "https": "http://..."} — ready for Request.set_proxy()
        """
        ...
```

Every provider receives the same `ProxyData` and uses it to construct provider-specific URLs. Adding a new field (e.g., `zone` for BrightData zones) means adding one field to `ProxyData` — no constructor signature changes across providers.

### BrightDataProvider (Shipped Implementation)

[Sign up for BrightData](https://brightdata.com/?referral=your_referral_id) — residential proxy network with geo-targeting, session persistence, and automatic IP rotation.

```python
from data_collector.proxy import ProxyProvider, ProxyData

class BrightDataProvider(ProxyProvider):
    """BrightData residential proxy provider."""

    def build_proxy_url(self, session_id: str) -> dict[str, str]:
        user = self.proxy_data.username
        if self.proxy_data.country:
            user = f"{user}-country-{self.proxy_data.country}"
        url = (f"http://{user}-session-{session_id}:{self.proxy_data.password}"
               f"@{self.proxy_data.host}:{self.proxy_data.port}")
        return {"http": url, "https": url}
```

### Adding a New Provider

Implement `build_proxy_url()` — one method, same `ProxyData`:

```python
class OxylabsProvider(ProxyProvider):
    """Oxylabs residential proxy provider."""

    def build_proxy_url(self, session_id: str) -> dict[str, str]:
        url = (f"http://{self.proxy_data.username}-sessid-{session_id}"
               f":{self.proxy_data.password}@{self.proxy_data.host}:{self.proxy_data.port}")
        return {"http": url, "https": url}
```

## IP Verification (Proxy Judges)

After the provider assigns an IP, the framework verifies it via proxy judges — lightweight endpoints that return your IP address. Multiple judges with failover ensure verification works even if one judge is down:

```python
PROXY_JUDGES = [
    "https://httpbin.org/ip",
    "https://api.ipify.org?format=json",
    "https://ifconfig.me/ip"
]
```

The verification flow:

1. Make a request through the proxy to the first judge URL
2. Parse the IP from the response
3. Sanity check: response content length < 365 bytes (prevents judge returning HTML error pages)
4. If the judge fails (timeout, error, invalid response), try the next judge
5. If all judges fail, retry with a new proxy session

```python
def _verify_ip(self, proxy_url: dict) -> str | None:
    """Try proxy judges with failover. Return IP string or None."""
    for judge_url in self.judges:
        try:
            req = Request(timeout=10, retries=1)
            req.set_proxy(proxy_url)
            response = req.get(judge_url)
            if len(response.content) < 365:
                return extract_ip(response.content)
        except Exception:
            continue
    return None
```

## IP Reservation

### ProxyReservation Table

The `ProxyReservation` table tracks which IPs are currently in use, preventing multiple apps from using the same IP on the same target domain:

```python
class ProxyReservation(Base):
    __tablename__ = "proxy_reservation"

    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)
    ip_address: Mapped[str] = mapped_column(String(45))          # IPv4 or IPv6
    target_domain: Mapped[str] = mapped_column(String(255))      # e.g., "gov.hr"
    app_id: Mapped[str] = mapped_column(String(64))              # Which app reserved it
    reserved_at: Mapped[datetime] = mapped_column(DateTime)      # When reserved
    ttl_seconds: Mapped[int] = mapped_column(Integer, default=1800)  # 30 min default
    released: Mapped[bool] = mapped_column(Boolean, default=False)   # Explicit release flag
```

**Database constraint — unique partial index:**

```sql
-- PostgreSQL
CREATE UNIQUE INDEX uq_proxy_reservation_ip_address
ON proxy_reservation (ip_address, target_domain)
WHERE released = false;

-- MSSQL (filtered index, same semantics)
CREATE UNIQUE INDEX uq_proxy_reservation_ip_address
ON proxy_reservation (ip_address, target_domain)
WHERE released = 0;
```

This index guarantees that no two active (unreleased) reservations can exist for the same IP + domain combination, regardless of application-level timing. It is the ultimate safety net against race conditions across threads, processes, and servers.

See [1.2. data-model.md](1.2.%20data-model.md) for full table specification.

### Lock Scope: Target Domain

Reservations are scoped by **target domain** — the website being scraped. Apps hitting the same domain can't use the same IP, regardless of which app group or parent they belong to. This prevents the target site from seeing multiple requests from the same IP that appear to come from different users/sessions.

### Atomic Reservation (Race Condition Safety)

The reservation check and insert must be **atomic**. Without this, two threads (or two separate apps scraping the same domain) could both see an IP as available and both reserve it:

```
Thread A: check IP → available         Thread B: check IP → available
Thread A: INSERT reservation            Thread B: INSERT reservation  ← duplicate!
```

The framework prevents this with a two-layer defense:

**Layer 1 — Atomic `_try_reserve()` method:**

```python
def _try_reserve(self, ip: str) -> bool:
    """Atomic check + reserve in a single transaction.

    Returns True if reservation succeeded, False if IP already taken.
    Works safely across threads, processes, and servers.
    """
    with self.database.create_session() as session:
        # Step 1: Release any TTL-expired reservation for this IP + domain
        session.execute(
            update(ProxyReservation)
            .where(
                ProxyReservation.ip_address == ip,
                ProxyReservation.target_domain == self.target_domain,
                ProxyReservation.released == False,
                func.now() > ProxyReservation.reserved_at + ttl_interval
            )
            .values(released=True)
        )

        # Step 2: Try INSERT — unique index is the arbiter
        try:
            session.add(ProxyReservation(
                ip_address=ip,
                target_domain=self.target_domain,
                app_id=self.app_id,
                reserved_at=datetime.now(),
                ttl_seconds=self.ttl_seconds
            ))
            session.commit()
            return True
        except IntegrityError:
            session.rollback()
            return False  # Another thread/app reserved it first
```

**Layer 2 — Unique partial index catches edge cases:**

Even if two transactions execute the UPDATE + INSERT simultaneously, the `uq_proxy_reservation_ip_address` unique index on `(ip_address, target_domain) WHERE released = false` causes the second INSERT to fail with `IntegrityError`. The framework catches this gracefully and retries with a new proxy session.

**Why both layers?**

| Layer | Purpose | Scope |
|-------|---------|-------|
| Unique partial index | DB-level guarantee — no duplicate active reservations ever | Threads, processes, servers |
| `IntegrityError` catch | Graceful application-level retry when index fires | Acquire loop retries with new session |
| TTL UPDATE in same TX | Cleans expired rows before INSERT attempt | Crash safety within the atomic flow |

**Why no deadlocks?** The pattern uses no `SELECT FOR UPDATE` — no row locks are held across statements. The UPDATE only touches expired rows (nobody else contends for those). The INSERT either succeeds atomically or fails with `IntegrityError` immediately. No blocking, no waiting.

### Race Condition Scenarios

**Scenario 1 — Two threads from the same app get the same IP:**

```
Thread A                                Thread B
────────                                ────────
verify_ip() → "1.2.3.4"                verify_ip() → "1.2.3.4"

_try_reserve("1.2.3.4"):               _try_reserve("1.2.3.4"):
  BEGIN TX                                BEGIN TX
  UPDATE expired → 0 rows                UPDATE expired → 0 rows
  INSERT (1.2.3.4, domain)               INSERT (1.2.3.4, domain)
  COMMIT ✓                               ← IntegrityError (unique index)
  return True                             ROLLBACK, return False

→ Uses proxy ✓                          → Retries with new session_id
                                        → Gets different IP → reserves ✓
```

**Scenario 2 — Two different apps targeting the same domain:**

Identical behavior — the database doesn't care if the competing transactions come from threads or processes. The unique index is the single arbiter.

### TTL-Based Auto-Expiry (Crash Safety)

If an app crashes without releasing its proxy reservation, the row stays in the database. TTL-based expiry handles this automatically — reservations older than their TTL are treated as expired and cleaned up during the next `_try_reserve()` call:

- **Default TTL:** 1800 seconds (30 minutes)
- **How it works:** The `_try_reserve()` UPDATE step releases expired reservations before attempting the INSERT
- **No cleanup job needed:** Stale rows are cleaned up organically as part of the acquisition flow; periodic cleanup can be run optionally to remove old released rows

This means a crashed app's proxy reservations auto-heal within 30 minutes without any manual intervention or dependency on the Manager process.

## ProxyManager

`ProxyManager` orchestrates the acquisition flow — provider, judges, and reservation:

```python
from data_collector.proxy import ProxyManager, BrightDataProvider, ProxyData, Proxy
from data_collector.request import Request

# All proxy config in one place
proxy_data = ProxyData(
    host="zproxy.lum-superproxy.io",
    port=22225,
    username="lum-customer-xxx",
    password="secret",
    country="hr"
)

# Create provider with ProxyData
provider = BrightDataProvider(proxy_data)

# Create manager for a specific target domain
proxy_mgr = ProxyManager(
    provider=provider,
    database=database,
    target_domain="gov.hr",
    app_id=app_id,
    ttl_seconds=1800,          # 30 min reservation TTL
    acquire_timeout=120         # Max 2 min to acquire a unique proxy
)

# Acquire a unique, reserved proxy
proxy = proxy_mgr.acquire(logger)

try:
    req = Request(timeout=120, retries=3)
    req.set_proxy(proxy.url)
    response = req.get("https://gov.hr/api/data")
    # ... process response ...
finally:
    proxy_mgr.release(proxy.ip_address)  # Always release on completion
```

### Acquisition Flow

```python
class ProxyManager:
    def __init__(self, provider: ProxyProvider, database: Database,
                 target_domain: str, app_id: str,
                 judges: list[str] | None = None,
                 ttl_seconds: int = 1800,
                 acquire_timeout: int = 120,
                 recheck_interval: int = 5):
        self.provider = provider
        self.database = database
        self.target_domain = target_domain
        self.app_id = app_id
        self.judges = judges or PROXY_JUDGES
        self.ttl_seconds = ttl_seconds
        self.acquire_timeout = acquire_timeout
        self.recheck_interval = recheck_interval

    def acquire(self, logger) -> Proxy:
        """Acquire a unique, reserved proxy for this domain.

        Returns:
            Proxy object with verified IP, URL dict, session ID, and target domain.

        Raises:
            ProxyAcquisitionTimeout — if no unique proxy found within timeout
        """
        start = datetime.now()
        while (datetime.now() - start).total_seconds() < self.acquire_timeout:
            # 1. Generate new session → provider builds proxy URL
            session_id = uuid.uuid4().hex
            proxy_url = self.provider.build_proxy_url(session_id)

            # 2. Verify IP via proxy judge (with failover)
            ip = self._verify_ip(proxy_url)
            if ip is None:
                logger.warning("All proxy judges failed, retrying with new session")
                continue

            # 3. Atomic reserve — INSERT-or-fail with unique index
            if self._try_reserve(ip):
                logger.info("Proxy acquired", ip=ip, domain=self.target_domain)
                return Proxy(
                    url=proxy_url,
                    ip_address=ip,
                    session_id=session_id,
                    target_domain=self.target_domain
                )

            # IP already reserved by another thread/app — retry with new session
            logger.debug("IP already reserved", ip=ip, domain=self.target_domain)
            sleep(self.recheck_interval)

        raise ProxyAcquisitionTimeout(
            f"No unique proxy acquired for {self.target_domain} in {self.acquire_timeout}s"
        )

    def release(self, ip_address: str):
        """Release proxy reservation — call on thread/session completion."""
        with self.database.create_session() as session:
            # UPDATE proxy_reservation SET released = true
            # WHERE ip_address = :ip AND app_id = :app_id AND released = false
            ...
```

## Ban Detection

| Signal | Action |
|--------|--------|
| HTTP 403 | Rotate proxy (release + acquire new) |
| HTTP 429 | Cooldown, retry with delay |
| CAPTCHA page | Route to captcha solver ([12. captcha.md](12.%20captcha.md)) |
| Connection refused | Mark proxy as failed, acquire new |
| Timeout | Retry once, then acquire new |

Ban detection integrates with the Request class error introspection methods (`is_blocked()`, `is_proxy_error()`) and `RequestMetrics` target health circuit breaker — see [4.4. request.md](4.4.%20request.md).

## Multi-Threaded Proxy Usage

Each thread acquires its own unique proxy via `ProxyManager` and releases it on completion. `RequestMetrics` (shared across threads) tracks per-proxy performance:

```python
from data_collector.request import Request, RequestMetrics
from data_collector.proxy import ProxyManager, BrightDataProvider

class CourtCases(BaseScraper):
    def collect(self):
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = {
                executor.submit(self.collect_detail, case, idx): case
                for idx, case in enumerate(self.work_list)
            }
            for future in as_completed(futures):
                if self.fatal_flag:
                    break
                future.result()

    def collect_detail(self, case, instance_id):
        """Per-thread: acquire proxy → fetch → parse → store → release."""
        proxy_mgr = ProxyManager(
            provider=self.proxy_provider,
            database=self.database,
            target_domain="example.com",
            app_id=self.app_id
        )
        proxy = proxy_mgr.acquire(self.logger)

        try:
            req = Request(timeout=120, retries=3, metrics=self.metrics)
            req.set_proxy(proxy.url)
            req.set_headers({"User-Agent": "Mozilla/5.0 ..."})

            response = req.get(f"https://example.com/case/{case.case_id}")

            if req.should_abort(self.logger, proxy_on=True):
                return

            data = self.parser.parse_case_detail(response.content)
            self.store([data])
            self.solved += 1
        finally:
            proxy_mgr.release(proxy.ip_address)  # Always release
```

After all threads complete, `metrics.log_stats()` includes per-proxy breakdown (success rate, latency) identified by `country:port` — no credentials logged.

## Configuration

| Setting | Default | Description |
|---------|---------|-------------|
| `proxy_judges` | `["httpbin.org/ip", "api.ipify.org", "ifconfig.me/ip"]` | Judge URLs for IP verification |
| `proxy_ttl_seconds` | `1800` | Reservation TTL — 30 min default |
| `proxy_acquire_timeout` | `120` | Max seconds to wait for unique proxy |
| `proxy_recheck_interval` | `5` | Seconds between retries when IP is reserved |
| `proxy_max_judge_failures` | `3` | Consecutive judge failures before fatal |

## Dependencies

- **Request class** ([4.4. request.md](4.4.%20request.md)) — proxy flows through `set_proxy()` to session
- **RequestMetrics** ([4.4. request.md](4.4.%20request.md)) — per-proxy performance tracking
- **Database** ([4.1. database.md](4.1.%20database.md)) — ProxyReservation table for IP locking
- **httpx** — HTTP client with proxy support (via Request class)
- Captcha solving ([12. captcha.md](12.%20captcha.md)) — for CAPTCHA-triggered proxy rotation
- Concurrency ([16. concurrency.md](16.%20concurrency.md)) — thread-safe proxy acquisition
