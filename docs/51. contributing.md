[← Back to index](1.%20index.md)

# Contributing Guide

## Overview

Guidelines for contributing to the Data Collector framework. This covers code standards, git workflow, testing requirements, and architectural rules.

## Development Setup

### Prerequisites

- Python 3.13+
- PostgreSQL 14+ (for integration tests)
- Git
- **Platform**: Developed and tested primarily on Windows, but fully deployable on Linux including Docker containers and cloud environments. CI runs on Linux (GitHub Actions).

### Environment Setup

```bash
# Clone the repository
git clone https://github.com/DraganMatesic/data_collector.git
cd data_collector

# Create virtual environment
python -m venv .venv
source .venv/bin/activate      # Linux/macOS
.venv\Scripts\activate         # Windows

# Install with dev dependencies
pip install -e ".[dev]"

# Configure database for tests
export DC_DB_DRIVER=postgresql
export DC_DB_HOST=localhost
export DC_DB_NAME=data_collector_test
export DC_DB_USER=postgres
export DC_DB_PASSWORD=postgres
```

## Code Standards

### Style

- **Formatter:** Ruff (replaces Black + isort)
- **Linter:** Ruff
- **Type checker:** mypy (strict mode)
- **Line length:** 120 characters
- **Quotes:** Double quotes for strings

```toml
# pyproject.toml
[tool.ruff]
line-length = 120
target-version = "py313"

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B", "SIM"]

[tool.mypy]
strict = true
```

### Naming Conventions

| Element | Convention | Example |
|---------|-----------|---------|
| Modules | `snake_case` | `log_settings.py` |
| Classes | `PascalCase` | `DatabaseSettings` |
| Functions | `snake_case` | `make_hash()` |
| Constants | `UPPER_SNAKE` | `NAMING_CONVENTION` |
| ORM tables | `PascalCase` class, `snake_case` `__tablename__` | `class Apps`, `__tablename__ = "apps"` |
| Database columns | `snake_case` | `next_run`, `date_created` |
| Enum members | `UPPER_SNAKE` | `RunStatus.RUNNING` |

### Import Order

```python
# 1. Standard library
import os
from pathlib import Path

# 2. Third-party
from sqlalchemy import Column, String
from pydantic_settings import BaseSettings

# 3. Framework (data_collector)
from data_collector.settings.main import DatabaseSettings
from data_collector.utilities.database.main import Database
```

### Docstrings

Use Google-style docstrings for public APIs:

```python
def make_hash(record: dict, columns: list[str]) -> str:
    """Generate SHA-256 hash from selected column values.

    Args:
        record: Dictionary of column name → value pairs.
        columns: Column names to include in the hash.

    Returns:
        Hexadecimal SHA-256 hash string.
    """
```

## Git Workflow

### Branch Naming

```
feat/short-description     # New features
fix/short-description      # Bug fixes
docs/short-description     # Documentation changes
refactor/short-description # Code restructuring
test/short-description     # Test additions
```

### Commit Messages

Follow [Conventional Commits](https://www.conventionalcommits.org/):

```
feat: add proxy rotation support
fix: handle null values in make_hash
docs: add orchestration specification
refactor: extract connector factory from Database class
test: add merge() edge case tests
chore: update dependencies
```

### Pull Request Process

1. Create a feature branch from `master`
2. Make changes with clear, focused commits
3. Ensure all tests pass: `pytest`
4. Ensure linting passes: `ruff check data_collector/`
5. Open PR with description following the template
6. Address review feedback
7. Squash-merge into `master`

### PR Template

```markdown
## Summary
Brief description of what this PR does.

## Changes
- Bullet list of specific changes

## Testing
- How was this tested?
- Any new tests added?

## Related
- Links to related issues or docs
```

## Testing

### Test Structure

```
tests/
├── unit/
│   ├── test_hashing.py         # Pure function tests
│   ├── test_converters.py
│   └── test_settings.py
├── integration/
│   ├── test_database.py        # Requires PostgreSQL
│   ├── test_merge.py
│   └── test_deploy.py
└── conftest.py                 # Shared fixtures
```

### Running Tests

```bash
# All tests
pytest

# Unit tests only
pytest tests/unit/

# Integration tests (requires database)
pytest tests/integration/

# With coverage
pytest --cov=data_collector --cov-report=html
```

### Test Guidelines

1. **Unit tests** should be fast, isolated, and require no external services
2. **Integration tests** can use a test database (configured via env vars)
3. Use `pytest` fixtures for setup/teardown
4. Name tests descriptively: `test_make_hash_handles_none_values`
5. Test edge cases: empty inputs, null values, Unicode, large datasets
6. Coverage target: 80%+ for core modules

### Fixtures Example

```python
import pytest
from data_collector.settings.main import DatabaseSettings
from data_collector.utilities.database.main import Database

@pytest.fixture
def db_settings():
    return DatabaseSettings(
        host="localhost",
        port=5432,
        name="data_collector_test",
        user="postgres",
        password="postgres",
        driver="postgresql"
    )

@pytest.fixture
def database(db_settings):
    db = Database(db_settings)
    yield db
    db.close()
```

## Architecture Rules

These rules preserve framework integrity. All contributions must follow them.

### 1. ORM Models Extend `Base`

All table models must inherit from `Base` (which combines `DeclarativeBase` + `BaseModel`):

```python
from data_collector.tables.shared import Base

class MyTable(Base):
    __tablename__ = "my_table"
    # ...
```

### 2. SHA Hashing for Change Detection

Use `SHAHashableMixin` or `bulk_hash()` for all data that goes through `merge()`:

```python
class MyTable(Base, SHAHashableMixin):
    __hash_columns__ = ["name", "value", "source"]
```

### 3. Settings via Pydantic

All configuration must go through Pydantic settings classes — never hardcode connection strings, paths, or credentials:

```python
from pydantic_settings import BaseSettings

class MyFeatureSettings(BaseSettings):
    model_config = SettingsConfigDict(env_prefix="DC_MY_FEATURE_")
    enabled: bool = True
```

### 4. Logging via Framework Logger

Use the framework's `LoggingService` — never use `print()` or bare `logging.getLogger()`:

```python
logger = logging_service.configure_logger()
logger.info("Processing complete", record_count=42)
```

### 5. No Direct SQL in Application Code

Use SQLAlchemy ORM and the `Database` class methods. Raw SQL is acceptable only in `Database` internals or migration scripts.

### 6. Feature Modules Are Optional

New features must not break the core if their dependencies are missing. Use `is_module_available()` for optional imports:

```python
from data_collector.utilities.functions.runtime import is_module_available

if is_module_available("pika"):
    from pika import BlockingConnection
```

## Release Process

1. Update version in `pyproject.toml`
2. Update [52. changelog.md](52.%20changelog.md) with release notes
3. Create PR: `release/vX.Y.Z`
4. After merge, tag: `git tag vX.Y.Z`
5. Push tag: `git push origin vX.Y.Z`
6. CI builds and publishes to PyPI

## Questions?

Open an issue on GitHub or reach out to the maintainer.
