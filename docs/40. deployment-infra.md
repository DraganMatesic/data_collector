[← Back to index](1.%20index.md)

# Deployment & Infrastructure

## Overview

Production deployment patterns for the Data Collector framework, covering containerization, CI/CD, scaling strategies, and configuration management.

Developed and tested primarily on Windows, but fully deployable on Linux including Docker containers and cloud environments.

## Docker

### Application Dockerfile

```dockerfile
FROM python:3.13-slim

WORKDIR /app

# System dependencies for database drivers
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq-dev \
    unixodbc-dev \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY pyproject.toml ./
RUN pip install --no-cache-dir .

# Copy application code
COPY data_collector/ ./data_collector/

# Non-root user
RUN useradd -m collector
USER collector

CMD ["python", "-m", "data_collector"]
```

### Docker Compose — Development

```yaml
version: "3.9"
services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: data_collector
      POSTGRES_USER: collector
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  rabbitmq:
    image: rabbitmq:3-management
    ports:
      - "5672:5672"
      - "15672:15672"

  collector:
    build: .
    environment:
      - DC_DB_DRIVER=postgresql
      - DC_DB_HOST=postgres
      - DC_DB_PORT=5432
      - DC_DB_NAME=data_collector
      - DC_DB_USER=collector
      - DC_DB_PASSWORD=${DB_PASSWORD}
    depends_on:
      - postgres
      - rabbitmq

volumes:
  pgdata:
```

### Docker Compose — Production

```yaml
version: "3.9"
services:
  manager:
    image: data-collector:${VERSION}
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        max_attempts: 3
    environment:
      - DC_DB_DRIVER=postgresql
      - DC_DB_HOST=${DB_HOST}
      - DC_DB_PORT=5432
      - DC_DB_NAME=${DB_NAME}
      - DC_DB_USER=${DB_USER}
      - DC_DB_PASSWORD=${DB_PASSWORD}
      - DC_LOG_SPLUNK_ENABLED=true
      - DC_LOG_SPLUNK_URL=${SPLUNK_HEC_URL}
      - DC_LOG_SPLUNK_TOKEN=${SPLUNK_HEC_TOKEN}
      - DC_RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672/
    volumes:
      - storage:/app/storage
    healthcheck:
      test: ["CMD", "python", "-c", "import data_collector; print('ok')"]
      interval: 30s
      timeout: 10s
      retries: 3

  dramatiq-worker:
    image: data-collector:${VERSION}
    command: ["python", "-m", "dramatiq", "data_collector.workers"]
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
        max_attempts: 3
    environment:
      - DC_DB_DRIVER=postgresql
      - DC_DB_HOST=${DB_HOST}
      - DC_DB_PORT=5432
      - DC_DB_NAME=${DB_NAME}
      - DC_DB_USER=${DB_USER}
      - DC_DB_PASSWORD=${DB_PASSWORD}
      - DC_RABBITMQ_URL=amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672/
    depends_on:
      - rabbitmq

  api:
    image: data-collector:${VERSION}
    command: ["uvicorn", "data_collector.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
    deploy:
      replicas: 2
    ports:
      - "8000:8000"
    environment:
      - DC_DB_DRIVER=postgresql
      - DC_DB_HOST=${DB_HOST}
      - DC_DB_NAME=${DB_NAME}
      - DC_API_JWT_SECRET=${JWT_SECRET}

volumes:
  storage:
```

## CI/CD Pipeline

### GitHub Actions

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [master, develop]
  pull_request:
    branches: [master]

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: test_db
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        ports:
          - 5432:5432

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.13"
      - run: pip install -e ".[dev]"
      - run: pytest --cov=data_collector --cov-report=xml
      - uses: codecov/codecov-action@v4

  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.13"
      - run: pip install ruff mypy
      - run: ruff check data_collector/
      - run: mypy data_collector/

  build:
    needs: [test, lint]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master'
    steps:
      - uses: actions/checkout@v4
      - uses: docker/build-push-action@v5
        with:
          push: true
          tags: ghcr.io/${{ github.repository }}:${{ github.sha }}
```

### Release Workflow

```yaml
# .github/workflows/release.yml
name: Release

on:
  push:
    tags: ["v*"]

jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.13"
      - run: pip install build twine
      - run: python -m build
      - run: twine upload dist/*
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_TOKEN }}
```

## Scaling Patterns

### Single Server

```
┌─────────────────────────┐
│  Server                 │
│  ├── Manager Process    │
│  ├── App Process 1..N   │
│  ├── PostgreSQL         │
│  └── Storage (/data)    │
└─────────────────────────┘
```

Suitable for up to ~20 concurrent apps. Manager spawns app processes directly.

### Multi-Server with RabbitMQ

```
┌──────────┐     ┌──────────────┐     ┌──────────┐
│ Manager  │────►│  RabbitMQ    │◄────│ Manager  │
│ Server A │     │  (commands)  │     │ Server B │
└──────────┘     └──────────────┘     └──────────┘
      │                                     │
      ▼                                     ▼
┌──────────┐                         ┌──────────┐
│ Apps     │                         │ Apps     │
│ 1..35    │                         │ 36..70   │
└──────────┘                         └──────────┘
      │                                     │
      └──────────► PostgreSQL ◄─────────────┘
```

RabbitMQ distributes commands across managers. Shared database for state.

### Containerized (Kubernetes)

```yaml
# Horizontal Pod Autoscaler for worker pods
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: collector-workers
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: collector-worker
  minReplicas: 2
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
```

## Configuration Management

### Environment Variables

All settings are configured via environment variables with the `DC_` prefix:

```bash
# Database
export DC_DB_DRIVER=postgresql
export DC_DB_HOST=db.example.com
export DC_DB_PORT=5432
export DC_DB_NAME=data_collector
export DC_DB_USER=collector
export DC_DB_PASSWORD=secret

# Logging
export DC_LOG_LEVEL=INFO
export DC_LOG_SPLUNK_ENABLED=true
export DC_LOG_SPLUNK_URL=https://splunk.example.com:8088
export DC_LOG_SPLUNK_TOKEN=token

# Notifications (pluggable channels: Telegram, Teams, Slack, email, webhooks)
export DC_NOTIFY_TELEGRAM_BOT_TOKEN=bot123:ABC
export DC_NOTIFY_TELEGRAM_CHAT_ID=-100123456
```

### Secret Management

| Method | Use Case |
|--------|----------|
| Environment variables | Simple deployments, Docker |
| `.env` files | Local development (never committed) |
| `SecretLoader` (AES-256) | Encrypted secrets file for deployments without vault |
| HashiCorp Vault | Enterprise secret management |
| Cloud KMS | AWS Secrets Manager, Azure Key Vault, GCP Secret Manager |

### Configuration Hierarchy

```
1. Environment variables       (highest priority)
2. .env file
3. SecretLoader encrypted file
4. Settings class defaults     (lowest priority)
```

## Database Infrastructure

### PostgreSQL Recommendations

| Setting | Development | Production |
|---------|-------------|------------|
| `max_connections` | 100 | 300+ |
| `shared_buffers` | 128MB | 25% of RAM |
| `work_mem` | 4MB | 64MB |
| `maintenance_work_mem` | 64MB | 512MB |
| `wal_level` | minimal | replica |

### Connection Pooling

For production with many concurrent apps, use PgBouncer:

```
Apps ──► PgBouncer (port 6432) ──► PostgreSQL (port 5432)
```

PgBouncer in `transaction` mode limits actual database connections while supporting many application connections.

### Backup Strategy

| Type | Frequency | Retention |
|------|-----------|-----------|
| `pg_dump` (logical) | Daily | 30 days |
| WAL archiving (PITR) | Continuous | 7 days |
| Full base backup | Weekly | 90 days |

## Network & Firewall

```
Internet ──► Reverse Proxy (nginx/Caddy)
                  │
                  ├──► API (8000)      [public, HTTPS]
                  ├──► Dashboard (8501) [internal, HTTPS]
                  │
             Internal Network
                  │
                  ├──► PostgreSQL (5432) [internal only]
                  ├──► RabbitMQ (5672)   [internal only]
                  └──► Splunk HEC (8088) [internal only]
```

## Monitoring Integration

See [41. monitoring.md](41.%20monitoring.md) for detailed observability setup.

## Dependencies

- Docker 24+
- Docker Compose v2
- PostgreSQL 14+ (recommended: 16)
- RabbitMQ 3.x (required for command dispatch + Dramatiq task queues)
- Python 3.13+
