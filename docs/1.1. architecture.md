[← Back to index](1.%20index.md)

# Architecture

## System Overview

Data Collector follows a **layered architecture** combining Clean Architecture principles with pipeline-stage separation — a natural fit for an ETL/data ingestion framework.

```
┌─────────────────────────────────────────────────────────────────────┐
│                       APPLICATION LAYER                              │
│  Developer-built apps: scrapers, API consumers, file processors,     │
│  OCR pipelines — each a standalone executable using framework APIs    │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  ┌─────────────────────────────────────────────────────────────────┐ │
│  │                    DOMAIN / CORE LAYER                           │ │
│  │                                                                   │ │
│  │  merge() + hash-based change detection    App lifecycle (Apps,   │ │
│  │  make_hash / bulk_hash / obj_diff         Runtime, AppDbObjects) │ │
│  │  SHAHashableMixin                         Dependency tracking    │ │
│  └─────────────────────────────────────────────────────────────────┘ │
│                                                                       │
│  ┌─────────────────────────────────────────────────────────────────┐ │
│  │                   INFRASTRUCTURE LAYER                           │ │
│  │                                                                   │ │
│  │  Database          Request class        Messaging                │ │
│  │  ┌────────────┐   ┌──────────────┐     ┌──────────────┐         │ │
│  │  │ PostgreSQL │   │ httpx        │     │ RabbitMQ     │         │ │
│  │  │ MSSQL      │   │ sync + async │     │ pika         │         │ │
│  │  │ (pluggable)│   │ sessions     │     │ Dramatiq     │         │ │
│  │  └────────────┘   │ retries      │     └──────────────┘         │ │
│  │                    │ proxy        │                               │ │
│  │  ORM (SQLAlchemy)  └──────────────┘     File I/O                 │ │
│  │  Deploy (schema)                        Storage management       │ │
│  └─────────────────────────────────────────────────────────────────┘ │
│                                                                       │
│  ┌─────────────────────────────────────────────────────────────────┐ │
│  │                  ADAPTERS / INTEGRATION LAYER                    │ │
│  │                                                                   │ │
│  │  Notifications         OCR Engines        Captcha Solvers        │ │
│  │  ┌───────────────┐    ┌─────────────┐    ┌──────────────┐       │ │
│  │  │ Telegram      │    │ Tesseract   │    │ AntiCaptcha  │       │ │
│  │  │ MS Teams      │    │ PaddleOCR   │    └──────────────┘       │ │
│  │  │ Slack         │    └─────────────┘                            │ │
│  │  │ Email         │                        SOAP / XML             │ │
│  │  │ Webhooks      │    PDF Processing      WSDL client            │ │
│  │  └───────────────┘    pdfplumber                                 │ │
│  └─────────────────────────────────────────────────────────────────┘ │
│                                                                       │
│  ┌─────────────────────────────────────────────────────────────────┐ │
│  │               PLATFORM / CROSS-CUTTING LAYER                     │ │
│  │                                                                   │ │
│  │  Logging Pipeline        Settings (Pydantic)    Secret Loader   │ │
│  │  QueueHandler → Queue    DatabaseSettings       AES-256-CBC     │ │
│  │  → QueueListener         LogSettings            PBKDF2          │ │
│  │  → RouterHandler         GeneralSettings                         │ │
│  │    ├─ Console                                   Hashing          │ │
│  │    ├─ Database            Profiling             SHA3-256         │ │
│  │    ├─ Splunk HEC          @fun_watch            Functions        │ │
│  │    └─ File (fallback)                           converters/math  │ │
│  └─────────────────────────────────────────────────────────────────┘ │
│                                                                       │
│  ┌─────────────────────────────────────────────────────────────────┐ │
│  │                  ORCHESTRATION LAYER                              │ │
│  │                                                                   │ │
│  │  Manager / Scheduler       Pipeline Infrastructure               │ │
│  │  Command dispatch          PipelineTask state tracking           │ │
│  │  Process lifecycle         Dramatiq workers                      │ │
│  │  Fatal detection           Watched directories → topic routing   │ │
│  └─────────────────────────────────────────────────────────────────┘ │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘
```

## Architecture Layers

### Application Layer
Developer-built applications that use the framework. Each app is a standalone Python process (scraper, API consumer, file processor, OCR pipeline). Apps import framework modules and follow standardized patterns — the framework handles cross-cutting concerns so developers focus on business logic.

### Domain / Core Layer
The business rules and invariants of the framework — independent of any specific database or external service:

- **Hash-based change detection** — `make_hash()`, `bulk_hash()`, `obj_diff()` implement deterministic SHA3-256 hashing for idempotent data synchronization
- **merge() pattern** — The core data synchronization mechanism: hash incoming records, compare against existing data, insert new / archive (or delete) removed — all in a single transaction
- **App lifecycle** — `Apps`, `AppGroups`, `AppParents`, `Runtime` models define how applications are registered, scheduled, and tracked
- **Dependency tracking** — `AppDbObjects` builds a real-time map of which apps touch which database objects

### Infrastructure Layer
Implementation details that touch the outside world — databases, HTTP, messaging, file systems:

- **Database** — `Database` class wraps SQLAlchemy 2.x session management. `BaseDBConnector` with `Postgres` and `MsSQL` subclasses abstracts connection strings, authentication variants (SQL, Windows, Kerberos), and driver quirks. The connector pattern is pluggable — new databases can be added by implementing `BaseDBConnector`
- **HTTP** — Centralized `Request` class built on httpx providing both sync and async methods. Handles sessions, retries, error handling, proxy integration, and response saving. Single class for all HTTP operations across the framework
- **Messaging** — RabbitMQ via pika for command distribution. Dramatiq for long-running task queues (OCR, NER pipelines)
- **ORM** — SQLAlchemy 2.x models with cross-database `auto_increment_column()`, naming conventions, and `Deploy` class for schema bootstrap
- **File I/O** — Storage management for downloads, file retention, and directory organization

### Adapters / Integration Layer
Translates between framework contracts and external APIs/services. Each adapter implements a common interface so implementations are swappable:

- **Notifications** — Pluggable alert channels: Telegram Bot API, Microsoft Teams webhooks, Slack API, email (SMTP), webhooks. Each channel implements the same notification interface
- **OCR engines** — `OCREngine` adapter pattern: Tesseract (default) and PaddleOCR (optional). Whole-document classification determines text vs image extraction path
- **PDF processing** — pdfplumber for native text extraction from PDFs
- **Captcha solving** — AntiCaptcha API integration for automated CAPTCHA resolution
- **SOAP / XML** — WSDL-based client for government and enterprise web services

### Platform / Cross-cutting Layer
Capabilities used everywhere, not tied to a specific domain:

- **Logging pipeline** — `QueueHandler` → `QueueListener` → `RouterHandler` → sinks (Console, Database, Splunk HEC). File-based fallback when sinks fail. Application code never blocks on log I/O
- **Settings** — Pydantic-based configuration with environment variable aliases (`DC_*` prefix). Type validation at startup, IDE autocompletion, sensible defaults
- **Secret management** — `SecretLoader` with AES-256-CBC encryption, PBKDF2 key derivation (100,000 iterations)
- **Hashing** — SHA3-256 with case normalization and whitespace removal via `SHAHashableMixin`
- **Functions** — Shared utilities: converters, math helpers, runtime checks
- **Profiling** — `@fun_watch` decorator for per-function timing, results stored in `FunctionLog` table

### Orchestration Layer
Coordinates multi-step, long-running workflows:

- **Manager / Scheduler** — Central process that polls the `Apps` table, launches apps as subprocesses based on `next_run`, and dispatches commands (start/stop/reset) via `command_flag`
- **Pipeline infrastructure** — Framework provides the infrastructure for document processing pipelines: base worker class, watched directory entry points (one per document type), topic-based RabbitMQ routing, `PipelineTask` state tracking table. Developers build specific workers per document type
- **Dramatiq workers** — Long-running task execution for OCR, NER, and batch processing via Dramatiq + RabbitMQ
- **Fatal detection** — Automatic app disabling after repeated consecutive failures

## Design Principles

### Convention Over Configuration
Sensible defaults at every level:
- `MainDatabaseSettings` loads from `DC_DB_MAIN_*` environment variables automatically
- `auto_increment_column()` detects the database type and uses the correct strategy (Identity vs Sequence)
- Default hash algorithm is SHA3-256 with case normalization and whitespace removal
- Logging defaults to database + console with 10,000-message queue

### Database-Agnostic Design
The `BaseDBConnector` abstraction with `Postgres` and `MsSQL` subclasses means application code never touches connection strings. Each connector handles authentication variants internally. The pattern is pluggable — additional databases can be added by implementing the `BaseDBConnector` interface.

### SHA-Based Change Detection
The `merge()` pattern is the core data synchronization mechanism:
1. Hash each incoming record with `make_hash()` or `bulk_hash()`
2. Fetch existing records from DB
3. Compare hash sets via `obj_diff()` to identify inserts and removals
4. Insert new, archive (or delete) removed — in a single transaction

### Queue-Decoupled Logging
Application code emits log records to a `QueueHandler`. A background `QueueListener` thread picks them up and routes through `RouterHandler` to all configured sinks. If a sink fails, the error and original log record are written to a local fallback file. The application never blocks on log I/O.

### Object Dependency Tracking
When `settings.map_objects=True`, every `merge()`, `query()`, `execute()`, `bulk_insert()`, and `delete()` call automatically records which database objects (tables, views, procedures) the app touched. This builds a real-time dependency graph stored in `AppDbObjects`.

## Package Structure

```
data_collector/
├── __init__.py                          # Package root, imports tables
├── secret_loader.py                     # AES-256-CBC encrypted secret management
│
├── settings/                            # Configuration management
│   ├── __init__.py                      # Exports GeneralSettings, MainDatabaseSettings
│   └── main.py                          # Pydantic settings: DatabaseSettings, LogSettings, etc.
│
├── tables/                              # SQLAlchemy ORM models
│   ├── __init__.py                      # Re-exports all models
│   ├── shared.py                        # Base (DeclarativeBase + BaseModel + naming conventions)
│   ├── apps.py                          # Apps, AppGroups, AppParents, AppDbObjects, codebooks
│   ├── log.py                           # Logs, CodebookLogLevel
│   ├── runtime.py                       # Runtime, CodebookRuntimeCodes
│   ├── deploy.py                        # Deploy class (create/drop/seed tables)
│   └── examples.py                      # ExampleTable for documentation
│
├── utilities/
│   ├── database/                        # Database abstraction (Infrastructure layer)
│   │   ├── __init__.py
│   │   ├── main.py                      # Database class, connectors, SHAHashableMixin, BaseModel
│   │   └── loaders.py                   # ODBC driver pre-flight checks
│   │
│   ├── functions/                       # Shared utility functions (Cross-cutting)
│   │   ├── __init__.py
│   │   ├── runtime.py                   # make_hash, bulk_hash, obj_diff, is_module_available
│   │   ├── converters.py               # object_to_dict, time converters, to_none
│   │   └── math.py                      # get_totals, get_totalm, get_totalh
│   │
│   └── log/                             # Async logging infrastructure (Cross-cutting)
│       ├── __init__.py
│       ├── main.py                      # LoggingService (queue-based logger setup)
│       ├── router.py                    # RouterHandler (multi-sink observer dispatch)
│       └── handlers.py                  # DatabaseHandler, SplunkHECHandler
│
└── tests/                               # Examples and test scripts
    ├── deploying_tables.py
    ├── database_connections.py
    ├── app_log_example.py
    └── ...
```

## Component Interaction

### Settings → Database → Application
```
Environment Variables (DC_DB_MAIN_*)
        │
        ▼
  MainDatabaseSettings (Pydantic)
        │
        ▼
  Database(settings) → BaseDBConnector → create_engine()
        │
        ▼
  create_session() → Application code (merge, query, execute...)
```

### Logging Pipeline
```
  app.logger.info("message")
        │
        ▼
  QueueHandler → Queue (max 10,000 messages)
        │
        ▼
  QueueListener (background thread)
        │
        ▼
  RouterHandler.emit(record)
        │
   ┌────┼────┬────────┐
   ▼    ▼    ▼        ▼
Console  DB  Splunk  File
                    (fallback)
```

### Object Dependency Tracking
```
  database.merge(objects, session, ...)
        │
        ▼
  _track_models_from_objects(objects) → {ModelClass, ...}
        │
        ▼
  register_models(models) → AppDbObjects table
        │
        ▼
  Dependency graph: App X uses Table Y on Server Z
```

### HTTP Request Flow
```
  app code
        │
        ▼
  Request.get() / Request.async_get()
        │
        ▼
  httpx client (session, cookies, headers)
        │
        ├─→ Retry logic (configurable attempts + backoff)
        ├─→ Proxy rotation (if configured)
        └─→ Response saving (if configured)
```

### Pipeline Processing Flow
```
  Watched directory (per document type)
        │
        ▼
  Dramatiq task published → RabbitMQ topic
        │
        ▼
  Worker picks up task → PipelineTask record created
        │
        ├─→ Stage 1: Extraction (PDF text / OCR)
        ├─→ Stage 2: Parsing / NER
        ├─→ Stage 3: Validation
        └─→ Stage 4: Load → Database
        │
        ▼
  PipelineTask status updated (completed / failed)
```

## Technology Stack

| Layer | Technology | Version |
|-------|-----------|---------|
| Language | Python | 3.13+ |
| ORM | SQLAlchemy | 2.0+ |
| Configuration | pydantic-settings | 2.9+ |
| Validation | Pydantic | 2.11+ |
| PostgreSQL driver | psycopg2-binary | latest |
| MSSQL driver | pyodbc | latest |
| HTTP client | httpx (sync + async) | latest |
| HTML parsing | BeautifulSoup4, lxml, html5lib | latest |
| Structured logging | structlog | latest |
| Data processing | pandas | latest |
| Messaging | pika (RabbitMQ) | latest |
| Task queue | Dramatiq | latest |
| PDF extraction | pdfplumber | latest |
| OCR | pytesseract, PaddleOCR (optional) | latest |
| Encryption | cryptography | latest |
| Profiling | `@fun_watch` decorator → FunctionLog | — |
| Env loading | python-dotenv | latest |
| Notifications | Telegram Bot API, MS Teams, Slack, SMTP | latest |

## Extension Points

### Adding a New Database Backend
Subclass `BaseDBConnector` in `utilities/database/main.py`:
```python
class MySQL(BaseDBConnector):
    def build_conn_string(self):
        host = self.get_host()
        return f"mysql+pymysql://{self.settings.username}:{self.settings.password}@{host}/{self.database_name}"
```
Then register in the `database_classes()` factory function.

### Adding a New Log Sink
Subclass `logging.Handler` and register via `LoggingService.append_sink()`:
```python
class SlackHandler(logging.Handler):
    def emit(self, record):
        # Send to Slack webhook
        ...

service = LoggingService(logger_name="myapp", db_engine=db.engine)
service.append_sink(SlackHandler(webhook_url="..."))
service.configure_logger()
```

### Adding a New Notification Channel
Implement the notification interface and register with the notification system:
```python
class DiscordNotifier(BaseNotifier):
    def send(self, message: str, level: str = "info"):
        # Send to Discord webhook
        ...
```

### Adding New Settings Classes
Inherit from `DatabaseSettings` for new database connections:
```python
class WarehouseSettings(DatabaseSettings):
    username: str = Field(..., alias="DC_DB_WAREHOUSE_USERNAME")
    password: str = Field(..., alias="DC_DB_WAREHOUSE_PASSWORD")
    # ...
```

### Adding New ORM Tables
Inherit from `Base` in `tables/shared.py`:
```python
from data_collector.tables.shared import Base
from data_collector.utilities.database.main import auto_increment_column

class MyTable(Base):
    __tablename__ = 'my_table'
    id = auto_increment_column()
    # ... columns
```

### Adding a Pipeline Worker
Extend the base worker class for a specific document type:
```python
class InvoiceWorker(BasePipelineWorker):
    document_type = "invoice"
    stages = ["extract", "parse", "validate", "load"]

    def extract(self, file_path: str) -> dict:
        # Document-specific extraction logic
        ...
```

## Security Architecture

### Secrets at Rest
- Secrets are encrypted with **AES-256-CBC** using PBKDF2-derived keys (100,000 iterations, SHA-256)
- Encrypted secrets stored as `secrets.env.enc` inside ZIP archives
- Decryption password provided via `DC_SECRET_PASSWORD` environment variable

### Environment Variable Scoping
- All framework variables use the `DC_` prefix to avoid collisions
- Secrets set at **user scope** (Windows Registry `HKEY_CURRENT_USER\Environment`, Linux `~/.bashrc`)
- Never at system scope — prevents privilege escalation

### Connection String Safety
- Connection strings constructed internally by `BaseDBConnector` subclasses
- Credentials never logged — `Database` class uses the engine object, not raw strings
- Pool configuration: `pool_size=20`, `max_overflow=0` (prevents connection exhaustion)

### No Secrets in Source Code
- All credentials loaded from environment variables via Pydantic `Field(alias="...")`
- `.env` files excluded from version control
- `SecretLoader` decrypts in memory only — never writes plaintext to disk
